{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c788b2d3-c8c7-4676-86d2-e01645f1af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "✅ Environment ready and all libraries imported.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas numpy scikit-learn matplotlib seaborn nltk spacy transformers datasets sentence-transformers faiss-cpu langdetect openpyxl accelerate torch torchaudio sentencepiece langid gradio librosa soundfile pydub ffmpeg-python\n",
    "\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML/NLP imports\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "print(\"✅ Environment ready and all libraries imported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033a8da3-adb6-4181-bb36-343ed9179de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded datasets:\n",
      "patients: (10, 10)\n",
      "appointments: (3, 6)\n",
      "vitals: (3, 10)\n",
      "labs: (5, 7)\n",
      "diagnoses: (1, 6)\n",
      "lifestyle: (10, 7)\n",
      "med_history: (5, 5)\n",
      "ml_preds: (5, 7)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path('data')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def safe_read_csv(path):\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to load {path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def safe_read_excel(path):\n",
    "    try:\n",
    "        return pd.read_excel(path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to load {path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# File paths\n",
    "DATA_DIR = Path('data')\n",
    "schemes_df = pd.read_excel(\"health_schemes.xlsx\")\n",
    "patients = pd.read_csv('patients.csv.txt')\n",
    "appointments = pd.read_csv('appointments.csv.txt')\n",
    "vitals = pd.read_csv('vitals.csv.txt')\n",
    "labs = pd.read_csv('lab_results.csv.txt')\n",
    "diagnoses = pd.read_csv('diagnoses.csv.txt')\n",
    "lifestyle = pd.read_csv('lifestyle.csv.txt')\n",
    "med_history = pd.read_csv('medical_history.csv.txt')\n",
    "ml_preds = pd.read_csv('ml_predictions.csv.txt')\n",
    "\n",
    "data = {\n",
    "    'patients': patients,\n",
    "    'appointments': appointments,\n",
    "    'vitals': vitals,\n",
    "    'labs': labs,\n",
    "    'diagnoses': diagnoses,\n",
    "    'lifestyle': lifestyle,\n",
    "    'med_history': med_history,\n",
    "    'ml_preds': ml_preds\n",
    "}\n",
    "\n",
    "print(\"✅ Loaded datasets:\")\n",
    "for name, df in data.items():\n",
    "    print(f\"{name}: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349d0df7-a004-4489-9074-6139796a35a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Patients dataset cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanvi\\AppData\\Local\\Temp\\ipykernel_28400\\2532306162.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  patients.fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = unicodedata.normalize('NFKC', str(text))\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Clean patient names\n",
    "patients['first_name'] = patients.get('first_name','').apply(normalize_text)\n",
    "patients['last_name'] = patients.get('last_name','').apply(normalize_text)\n",
    "patients.fillna('', inplace=True)\n",
    "print(\"✅ Patients dataset cleaned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e958ce-12c2-4627-85a2-5e6488750c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Unified patient profiles sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>gender</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email</th>\n",
       "      <th>address</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lifestyle_id</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_consumption</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>diet_type</th>\n",
       "      <th>sleep_hours_per_night</th>\n",
       "      <th>condition_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>1980-05-15</td>\n",
       "      <td>Male</td>\n",
       "      <td>O+</td>\n",
       "      <td>555-0101</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Current</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>Sedentary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>[Hypertension]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Smith</td>\n",
       "      <td>1975-08-22</td>\n",
       "      <td>Female</td>\n",
       "      <td>A-</td>\n",
       "      <td>555-0102</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>Never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id first_name last_name date_of_birth  gender blood_type  \\\n",
       "0           1       John       Doe    1980-05-15    Male         O+   \n",
       "1           2       Jane     Smith    1975-08-22  Female         A-   \n",
       "\n",
       "  phone_number email address created_at  lifestyle_id smoking_status  \\\n",
       "0     555-0101                                      1        Current   \n",
       "1     555-0102                                      2          Never   \n",
       "\n",
       "  alcohol_consumption activity_level  diet_type  sleep_hours_per_night  \\\n",
       "0               Heavy      Sedentary        NaN                    5.5   \n",
       "1                 NaN       Moderate        NaN                    7.0   \n",
       "\n",
       "   condition_name  \n",
       "0  [Hypertension]  \n",
       "1             NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge with lifestyle and medical history\n",
    "patient_profiles = patients.copy()\n",
    "\n",
    "# Merge lifestyle\n",
    "if not lifestyle.empty:\n",
    "    patient_profiles = patient_profiles.merge(lifestyle, on='patient_id', how='left')\n",
    "\n",
    "# Merge medical history as list\n",
    "if not med_history.empty:\n",
    "    mh_summary = med_history.groupby('patient_id')['condition_name'].apply(list).reset_index()\n",
    "    patient_profiles = patient_profiles.merge(mh_summary, on='patient_id', how='left')\n",
    "\n",
    "print(\"✅ Unified patient profiles sample:\")\n",
    "display(patient_profiles.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ef801cc-6aee-4494-b483-3d79061e5f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is John Doe's latest cholesterol level?</td>\n",
       "      <td>get_lab_result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Show John Doe's blood pressure readings</td>\n",
       "      <td>get_vitals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List diagnoses for John Doe</td>\n",
       "      <td>get_diagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is John Doe's cardio risk prediction?</td>\n",
       "      <td>get_risk_prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is Jane Smith's latest cholesterol level?</td>\n",
       "      <td>get_lab_result</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text               intent\n",
       "0    What is John Doe's latest cholesterol level?       get_lab_result\n",
       "1         Show John Doe's blood pressure readings           get_vitals\n",
       "2                     List diagnoses for John Doe        get_diagnosis\n",
       "3      What is John Doe's cardio risk prediction?  get_risk_prediction\n",
       "4  What is Jane Smith's latest cholesterol level?       get_lab_result"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "synthetic_queries = []\n",
    "for _, row in patients.iterrows():\n",
    "    name = f\"{row.get('first_name','')} {row.get('last_name','')}\".strip()\n",
    "    if not name: continue\n",
    "    synthetic_queries.append((f\"What is {name}'s latest cholesterol level?\", 'get_lab_result'))\n",
    "    synthetic_queries.append((f\"Show {name}'s blood pressure readings\", 'get_vitals'))\n",
    "    synthetic_queries.append((f\"List diagnoses for {name}\", 'get_diagnosis'))\n",
    "    synthetic_queries.append((f\"What is {name}'s cardio risk prediction?\", 'get_risk_prediction'))\n",
    "\n",
    "syn_df = pd.DataFrame(synthetic_queries, columns=['text','intent'])\n",
    "display(syn_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7182dccf-b984-4424-88f7-00e2f5e48c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n",
      "cholesterol\n"
     ]
    }
   ],
   "source": [
    "def extract_patient_name(text):\n",
    "    for _, row in patients.iterrows():\n",
    "        full = f\"{row.get('first_name','')} {row.get('last_name','')}\".strip()\n",
    "        if full.lower() in text.lower():\n",
    "            return full\n",
    "    return None\n",
    "\n",
    "def extract_test_name(text):\n",
    "    tests = ['cholesterol', 'hba1c', 'glucose', 'blood pressure', 'bp']\n",
    "    for test in tests:\n",
    "        if test.lower() in text.lower():\n",
    "            return test\n",
    "    return None\n",
    "\n",
    "# Demo\n",
    "print(extract_patient_name(\"What is John Doe's cholesterol level?\"))\n",
    "print(extract_test_name(\"What is John Doe's cholesterol level?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69c0b90-652b-4643-af76-a276d0f4b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index for labs ready\n"
     ]
    }
   ],
   "source": [
    "# FAISS index for lab values\n",
    "if not labs.empty:\n",
    "    embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    texts = [f\"{r['test_name']}: {r['test_value']} {r['unit']}\" for _, r in labs.iterrows()]\n",
    "    embeddings = embedder.encode(texts, convert_to_numpy=True)\n",
    "    index_labs = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index_labs.add(embeddings)\n",
    "    print(\"✅ FAISS index for labs ready\")\n",
    "else:\n",
    "    index_labs = None\n",
    "    print(\"⚠️ Labs dataset empty, skipping FAISS embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d2b802-b96b-4967-975f-f78854d242a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Flan-T5 chat pipeline ready\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "chat_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "print(\"✅ Flan-T5 chat pipeline ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d44dae-e763-4e69-bdcf-8c93e305c715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Translation pipeline ready\n"
     ]
    }
   ],
   "source": [
    "import langid\n",
    "\n",
    "SUPPORTED_LANGS = {\"en\": \"English\", \"hi\": \"Hindi\"}\n",
    "MMS_TTS_CODES = {\"en\": \"eng\", \"hi\": \"hin\"}\n",
    "\n",
    "# IndicTrans2 models\n",
    "en_hi_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\")\n",
    "en_hi_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\")\n",
    "hi_en_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-hi-en\")\n",
    "hi_en_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-hi-en\")\n",
    "\n",
    "def detect_language_safe(text):\n",
    "    try:\n",
    "        lid, _ = langid.classify(text)\n",
    "        return lid if lid in SUPPORTED_LANGS else 'en'\n",
    "    except:\n",
    "        return 'en'\n",
    "\n",
    "def translate_to_english(text):\n",
    "    lang = detect_language_safe(text)\n",
    "    if lang == \"en\": return text, \"en\"\n",
    "    inputs = hi_en_tokenizer([text], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = hi_en_model.generate(**inputs, max_new_tokens=512)\n",
    "    return hi_en_tokenizer.batch_decode(outputs, skip_special_tokens=True)[0], lang\n",
    "\n",
    "def translate_from_english(text, target_lang):\n",
    "    if target_lang == \"en\": return text\n",
    "    inputs = [f\">>hi<< {text}\"]\n",
    "    tok = en_hi_tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    out = en_hi_model.generate(**tok, max_new_tokens=512)\n",
    "    return en_hi_tokenizer.batch_decode(out, skip_special_tokens=True)[0]\n",
    "\n",
    "print(\"✅ Translation pipeline ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "642fdd59-aa08-4abb-a504-ed04e4711006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a02da000574747b52157a982dd300b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index built for 20 govt schemes\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Prepare KB entries from schemes\n",
    "if not schemes_df.empty:\n",
    "    kb_entries = [\n",
    "        {\"id\": i, \"text\": row[\"Description\"]}\n",
    "        for i, row in schemes_df.iterrows() if pd.notna(row.get(\"Description\"))\n",
    "    ]\n",
    "else:\n",
    "    kb_entries = []\n",
    "\n",
    "# Build FAISS index\n",
    "if kb_entries:\n",
    "    embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    texts = [e['text'] for e in kb_entries]\n",
    "    emb = embed_model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "    faiss.normalize_L2(emb)\n",
    "    idx = faiss.IndexFlatIP(emb.shape[1])\n",
    "    idx.add(emb)\n",
    "    index_schemes = idx\n",
    "    embedder_schemes = embed_model\n",
    "    with open('kb_meta.json','w') as f:\n",
    "        json.dump(kb_entries, f)\n",
    "    print(f\"✅ FAISS index built for {len(kb_entries)} govt schemes\")\n",
    "else:\n",
    "    index_schemes = None\n",
    "    embedder_schemes = None\n",
    "    print(\"⚠️ No schemes to index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb361c5c-f56e-4938-ab1c-faa8c43b3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOVT_KEYWORDS = [\"scheme\", \"government\", \"govt\", \"योजना\", \"सरकारी\", \"आयुष्मान\", \"health plan\"]\n",
    "\n",
    "def is_govt_query(user_text):\n",
    "    text_lower = user_text.lower()\n",
    "    return any(k.lower() in text_lower for k in GOVT_KEYWORDS)\n",
    "\n",
    "def fetch_govt_scheme(user_text, top_k=3):\n",
    "    if not index_schemes or not kb_entries:\n",
    "        return None\n",
    "    if not is_govt_query(user_text):\n",
    "        return None\n",
    "\n",
    "    query_emb = embedder_schemes.encode([user_text], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(query_emb)\n",
    "    D, I = index_schemes.search(query_emb, top_k)\n",
    "    schemes = [kb_entries[i][\"text\"] for i in I[0] if i < len(kb_entries)]\n",
    "    if schemes:\n",
    "        return \"Here are some government schemes you may be eligible for:\\n\" + \"\\n\".join(f\"- {s}\" for s in schemes)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d99f42ee-aece-4423-b44c-23d023acae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_medical_advice(user_text):\n",
    "    prompt = f\"Provide safe, informative, concise medical advice:\\n{user_text}\"\n",
    "    output = chat_pipeline(prompt, max_new_tokens=150)\n",
    "    return output[0]['generated_text']\n",
    "\n",
    "def fetch_personalized_response(user_text):\n",
    "    # Translate to English\n",
    "    text_en, src_lang = translate_to_english(user_text)\n",
    "\n",
    "    # Govt schemes\n",
    "    scheme_resp = fetch_govt_scheme(text_en)\n",
    "\n",
    "    # Prompt for chat model\n",
    "    prompt = f\"User asked: {text_en}\\n\"\n",
    "    if scheme_resp:\n",
    "        prompt += f\"Relevant government schemes:\\n{scheme_resp}\\n\"\n",
    "    prompt += \"Now give a safe, concise medical advice if applicable.\"\n",
    "\n",
    "    answer_en = chat_pipeline(prompt, max_new_tokens=200)[0]['generated_text']\n",
    "\n",
    "    # Translate back\n",
    "    answer_out = translate_from_english(answer_en, src_lang)\n",
    "    return answer_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b9b722a-8ae1-41ad-8fb0-27935a583873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cell 15: Open-ended AI inference\n",
    "# ------------------------------\n",
    "def infer_final(query, user_lang='auto'):\n",
    "    \"\"\"\n",
    "    Generates AI response for any health-related or consultation query.\n",
    "    Handles:\n",
    "    - Language detection and translation\n",
    "    - Govt scheme suggestions if relevant\n",
    "    - AI-generated medical advice / consultation\n",
    "    - Translation back to user language\n",
    "    \"\"\"\n",
    "    # 1️⃣ Detect user language\n",
    "    lang = detect_language_safe(query) if user_lang == 'auto' else user_lang\n",
    "\n",
    "    # 2️⃣ Translate to English if needed\n",
    "    translated_q = query\n",
    "    if lang != 'en' and use_translator:\n",
    "        translated_q = translate_to_en(query, src_lang=lang)\n",
    "\n",
    "    # 3️⃣ Extract patient info if present\n",
    "    patient = extract_patient_name(translated_q)\n",
    "    test = extract_test_name(translated_q)\n",
    "\n",
    "    # 4️⃣ Fetch govt scheme if query is relevant\n",
    "    scheme_resp = None\n",
    "    if is_govt_query(translated_q) and 'kb_entries' in globals() and kb_entries:\n",
    "        scheme_resp = fetch_govt_scheme(translated_q)\n",
    "\n",
    "    # 5️⃣ Prepare AI prompt for Flan-T5 (or your chat model)\n",
    "    prompt = f\"User asked: {translated_q}\\n\"\n",
    "    if scheme_resp:\n",
    "        prompt += f\"Relevant government schemes:\\n{scheme_resp}\\n\"\n",
    "    prompt += \"Provide a safe, polite, and concise medical advice or consultation if applicable.\"\n",
    "\n",
    "    # 6️⃣ Generate AI response\n",
    "    try:\n",
    "        result_en = chat_pipeline(prompt, max_new_tokens=200)[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        result_en = f\"Error generating AI response: {e}\"\n",
    "\n",
    "    # 7️⃣ Translate back to user's language if needed\n",
    "    result_final = result_en\n",
    "    if lang != 'en' and use_translator:\n",
    "        result_final = translate_from_en(result_en, lang)\n",
    "\n",
    "    # 8️⃣ Return all useful info\n",
    "    return {\n",
    "        \"query_original\": query,\n",
    "        \"user_lang\": lang,\n",
    "        \"query_translated\": translated_q,\n",
    "        \"scheme_suggestion\": scheme_resp,\n",
    "        \"answer_english\": result_en,\n",
    "        \"answer_final\": result_final,\n",
    "        \"patient_name\": patient,\n",
    "        \"test_name\": test\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa335b15-3aef-4c3e-bae6-b9eb56149569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write as wavwrite\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "\n",
    "device_id = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "def get_tts_pipeline_for_lang(lang_2):\n",
    "    if lang_2 not in MMS_TTS_CODES:\n",
    "        raise ValueError(f\"TTS not configured for: {lang_2}\")\n",
    "    code3 = MMS_TTS_CODES[lang_2]\n",
    "    model_id = f\"facebook/mms-tts-{code3}\"\n",
    "    tts = pipeline(\"text-to-speech\", model=model_id, device=device_id)\n",
    "    return tts\n",
    "\n",
    "def synthesize_speech(text, lang_2, out_wav=\"tts_output.wav\"):\n",
    "    tts = get_tts_pipeline_for_lang(lang_2)\n",
    "    out = tts(text)\n",
    "    audio = out[\"audio\"]\n",
    "    sr = out[\"sampling_rate\"]\n",
    "    audio_int16 = (audio * 32767).astype(np.int16)\n",
    "    wavwrite(out_wav, sr, audio_int16)\n",
    "    return out_wav\n",
    "\n",
    "# Demo\n",
    "# path = synthesize_speech(\"नमस्ते, आप कैसे हैं?\", \"hi\", \"hello_hi.wav\")\n",
    "# display(audio(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0001be5-e9ca-462a-82bf-89d60d327bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilingual_infer(user_text, target_lang=None):\n",
    "    # Detect language & translate\n",
    "    text_en, src_lang = translate_to_english(user_text)\n",
    "\n",
    "    # AI medical advice\n",
    "    medical_resp = fetch_medical_advice(text_en)\n",
    "\n",
    "    # Govt schemes if query detected\n",
    "    scheme_resp = fetch_govt_scheme(text_en) if is_govt_query(text_en) else None\n",
    "\n",
    "    ans_en = medical_resp\n",
    "    if scheme_resp:\n",
    "        ans_en += \"\\n\\nYou may also be eligible for these government schemes:\\n\" + scheme_resp\n",
    "\n",
    "    out_lang = target_lang or src_lang\n",
    "    ans_out = translate_from_english(ans_en, out_lang)\n",
    "    \n",
    "    return {\n",
    "        \"src_lang\": src_lang,\n",
    "        \"out_lang\": out_lang,\n",
    "        \"input_english\": text_en,\n",
    "        \"answer_english\": ans_en,\n",
    "        \"answer_final\": ans_out,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "707f8deb-e2df-4e17-a6f8-90a6b1d32485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from typing import Optional\n",
    "\n",
    "def gradio_pipeline(input_text: str, input_audio: Optional[str], force_output_lang: Optional[str]):\n",
    "    text = input_text.strip() if input_text else \"\"\n",
    "    target_lang = force_output_lang if force_output_lang in SUPPORTED_LANGS else None\n",
    "\n",
    "    if not text and input_audio:\n",
    "        # Optional: implement audio transcription\n",
    "        text = \"[Audio transcription placeholder]\"  # Replace with actual transcription function\n",
    "\n",
    "    if not text:\n",
    "        return \"No input received.\", None, None, None, None, None\n",
    "\n",
    "    result = multilingual_infer(text, target_lang=target_lang)\n",
    "\n",
    "    # TTS\n",
    "    try:\n",
    "        wav_path = synthesize_speech(result[\"answer_final\"], result[\"out_lang\"], out_wav=\"response_tts.wav\")\n",
    "    except Exception as e:\n",
    "        print(f\"TTS error: {e}\")\n",
    "        wav_path = None\n",
    "\n",
    "    return (\n",
    "        result[\"src_lang\"],\n",
    "        result[\"out_lang\"],\n",
    "        result[\"input_english\"],\n",
    "        result[\"answer_english\"],\n",
    "        result[\"answer_final\"],\n",
    "        wav_path\n",
    "    )\n",
    "\n",
    "# Launch Gradio\n",
    "demo = gr.Interface(\n",
    "    fn=gradio_pipeline,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Text input\"),\n",
    "        gr.Audio(sources=[\"microphone\",\"upload\"], type=\"filepath\", label=\"Or speak/upload audio\"),\n",
    "        gr.Dropdown(choices=list(SUPPORTED_LANGS.keys()), value=None, label=\"Force output language\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Detected input language\"),\n",
    "        gr.Textbox(label=\"Output language\"),\n",
    "        gr.Textbox(label=\"Input in English\"),\n",
    "        gr.Textbox(label=\"Answer in English\"),\n",
    "        gr.Textbox(label=\"Final Answer\"),\n",
    "        gr.Audio(label=\"TTS Audio\")\n",
    "    ],\n",
    "    title=\"Multilingual AI Health + Govt Scheme Chatbot\",\n",
    "    description=\"Ask medical questions or govt scheme queries in English/Hindi. Outputs text + speech.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6264f4d6-5441-42bb-b2b7-98e4688bf0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
